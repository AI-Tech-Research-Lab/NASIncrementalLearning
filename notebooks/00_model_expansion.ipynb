{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba4e49e-8066-4dd6-97fe-6238730bc8ac",
   "metadata": {},
   "source": [
    "This notebook is to understand the NAS pipeline and the differen \"modules/sections\" of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb0b6c0-5209-430b-b288-db55a693936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _configs import OFA_MODEL_PATH\n",
    "\n",
    "import ofa.model_zoo as ofa\n",
    "import torch\n",
    "\n",
    "from search_space import get_search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f016978-c578-49c6-ae5c-e0e9b5e2f4e5",
   "metadata": {},
   "source": [
    "## 1. Understand the models definition\n",
    "\n",
    "We will check the sampled model and how to define it from the OFA network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96d8738-7be6-4d74-a61d-12127c23c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ofa_mobilenet( weights_path: str | None ):\n",
    "    \"\"\" Loads the MobileNetV3 model class and the corresponding weights \"\"\"\n",
    "    \n",
    "    network = ofa.OFAMobileNetV3(\n",
    "        dropout_rate=0,\n",
    "        width_mult=1.0,\n",
    "        ks_list=[3, 5, 7],\n",
    "        expand_ratio_list=[3, 4, 6],\n",
    "        depth_list=[2, 3, 4],\n",
    "    )\n",
    "    \n",
    "    init_weights = torch.load(weights_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    network.load_state_dict(init_weights)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd1f7b-074e-436e-b313-57bd37f5c247",
   "metadata": {},
   "source": [
    "Define the space and the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8774c0da-c548-4ec0-8c1e-059675ab8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofa_network = ofa_mobilenet( OFA_MODEL_PATH )\n",
    "space = get_search_space('mobilenetv3-growth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77d023-6564-4931-96c6-feb21b4f0880",
   "metadata": {},
   "source": [
    "Sample an architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d0fe5f-17db-4144-9c8d-ca3ef101ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled architecture:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'depths': [3, 3, 3, 3, 3],\n",
       " 'ksizes': [5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 5, 3],\n",
       " 'widths': [3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 3, 4, 3],\n",
       " 'resolution': 152}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = space.sample(n_samples=1)[0]\n",
    "base_arch = { k: sample[k] for k in sample if (k != 'direction') }\n",
    "scale_dir = [1, 0, 0]\n",
    "\n",
    "print(\"Sampled architecture:\")\n",
    "base_arch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d270c-3a06-4239-9ca5-33cbe2af4f20",
   "metadata": {},
   "source": [
    "Get the expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96aacfc4-5350-4fe6-94a0-db960257ea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded architecture:\n",
      "  - By: [1, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'depths': [3, 3, 3, 3, 4],\n",
       " 'ksizes': [5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 5, 3, 3],\n",
       " 'widths': [3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 3, 4, 3, 3],\n",
       " 'resolution': 152}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_arch = space.apply_scaling(base_arch, scale_dir)\n",
    "print(\"Expanded architecture:\")\n",
    "print(\"  - By:\", scale_dir)\n",
    "expanded_arch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90db55-e1e7-430e-a50c-1719243cb9bc",
   "metadata": {},
   "source": [
    "Get the model weights for the base and expanded architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "749a9f65-3e09-4fdf-b52d-be504dff26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofa_network.set_active_subnet(ks=base_arch['ksizes'], e=base_arch['widths'], d=base_arch['depths'])\n",
    "base_network = ofa_network.get_active_subnet(preserve_weight=True)\n",
    "\n",
    "ofa_network.set_active_subnet(ks=expanded_arch['ksizes'], e=expanded_arch['widths'], d=expanded_arch['depths'])\n",
    "expanded_network = ofa_network.get_active_subnet(preserve_weight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a2a62-2d17-4743-86f7-18ea0318e19f",
   "metadata": {},
   "source": [
    "### 1. Exploration of the expanded architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6636b1b6-f702-4935-ab78-b932d44c2002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model blocks: 16\n",
      "Expanded model blocks: 17\n"
     ]
    }
   ],
   "source": [
    "print(\"Base model blocks:\", len(base_network.blocks) )\n",
    "print(\"Expanded model blocks:\", len(expanded_network.blocks) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "512a52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ofa.utils.layers import (\n",
    "    SEModule,\n",
    "    MBConvLayer,\n",
    "    ResidualBlock,\n",
    "    IdentityLayer,\n",
    "    ConvLayer,\n",
    "    LinearLayer,\n",
    ")\n",
    "from ofa.utils.pytorch_modules import MyGlobalAvgPool2d, Hsigmoid, Hswish\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def transfer_linear_weights(source_linear: nn.Linear, target_linear: nn.Linear) -> None:\n",
    "    \"\"\"\n",
    "    Copy weights from source to target linear layer.\n",
    "\n",
    "    ### Args:\n",
    "        `source_linear (nn.Linear)`: Source linear layer\n",
    "        `target_linear (nn.Linear)`: Target linear layer with potentially more features\n",
    "    \"\"\"\n",
    "    out_features, in_features = source_linear.weight.shape\n",
    "\n",
    "    # Copy existing weights\n",
    "    target_linear.weight.data[:out_features, :in_features] = source_linear.weight.data\n",
    "    if source_linear.bias is not None:\n",
    "        target_linear.bias.data[:out_features] = source_linear.bias.data\n",
    "\n",
    "def transfer_conv_weights(source_conv: nn.Conv2d, target_conv: nn.Conv2d) -> None:\n",
    "    \"\"\"\n",
    "    Copy weights from source to target conv layer, centering the kernel.\n",
    "\n",
    "    ### Args:\n",
    "        `source_conv (nn.Conv2d)`: Source convolution layer\n",
    "        `target_conv (nn.Conv2d)`: Target convolution layer with potentially more channels\n",
    "    \"\"\"\n",
    "    source_weight = source_conv.weight\n",
    "    out_c, in_c, k_h, k_w = source_weight.shape\n",
    "    \n",
    "    # Get target dimensions\n",
    "    _, _, target_k_h, target_k_w = target_conv.weight.shape\n",
    "    \n",
    "    # Calculate padding for centering when target kernel is larger\n",
    "    if target_k_h >= k_h and target_k_w >= k_w:\n",
    "        pad_h = (target_k_h - k_h) // 2\n",
    "        pad_w = (target_k_w - k_w) // 2\n",
    "        \n",
    "        # Copy existing weights to the center\n",
    "        target_conv.weight.data[:out_c, :in_c, pad_h:pad_h+k_h, pad_w:pad_w+k_w] = source_weight\n",
    "\n",
    "    # Calculate cropping for centering when target is smaller than source\n",
    "    else:\n",
    "        crop_h = (k_h - target_k_h) // 2\n",
    "        crop_w = (k_w - target_k_w) // 2\n",
    "        \n",
    "        # Copy center weights from source to target\n",
    "        target_conv.weight.data[:out_c, :in_c, :, :] = source_weight[:out_c, :in_c, \n",
    "                                                                     crop_h:crop_h+target_k_h,\n",
    "                                                                     crop_w:crop_w+target_k_w]\n",
    "\n",
    "def transfer_bn_weights(source_bn: nn.BatchNorm2d, target_bn: nn.BatchNorm2d) -> None:\n",
    "    \"\"\"\n",
    "    Copy weights from source to target batch norm layer.\n",
    "\n",
    "    ### Args:\n",
    "        `source_bn (nn.BatchNorm2d)`: Source batch normalization layer\n",
    "        `target_bn (nn.BatchNorm2d)`: Target batch normalization layer\n",
    "    \"\"\"\n",
    "    num_features = source_bn.num_features\n",
    "\n",
    "    # Copy existing parameters and buffers\n",
    "    target_bn.weight.data[:num_features] = source_bn.weight.data\n",
    "    target_bn.bias.data[:num_features] = source_bn.bias.data\n",
    "    target_bn.running_mean.data[:num_features] = source_bn.running_mean.data\n",
    "    target_bn.running_var.data[:num_features] = source_bn.running_var.data\n",
    "\n",
    "def transfer_se_module_weights(source_se: SEModule, target_se: SEModule) -> None:\n",
    "    \"\"\"\n",
    "    Copy weights for Squeeze-and-Excitation module.\n",
    "\n",
    "    Args:\n",
    "        source_se (SEModule): Source SE module\n",
    "        target_se (SEModule): Target SE module\n",
    "    \"\"\"\n",
    "    # SE modules typically contain fc layers\n",
    "    if hasattr(source_se, \"fc\") and source_se.fc:\n",
    "        for source_layer, target_layer in zip(source_se.fc, target_se.fc):\n",
    "            if isinstance(source_layer, nn.Linear):\n",
    "                transfer_linear_weights(source_layer, target_layer)\n",
    "\n",
    "def transfer_convlayer_weights(source_conv: ConvLayer, target_conv: ConvLayer) -> None:\n",
    "    \"\"\"\n",
    "    Copy weights from source to target conv layer.\n",
    "\n",
    "    ### Args:\n",
    "        `source_conv (ConvLayer)`: Source convolution layer\n",
    "        `target_conv (ConvLayer)`: Target convolution layer\n",
    "    \"\"\"\n",
    "    if hasattr(source_conv, \"conv\") and source_conv.conv:\n",
    "        transfer_block_weights(source_conv.conv, target_conv.conv)\n",
    "\n",
    "    if hasattr(source_conv, \"bn\") and source_conv.bn:\n",
    "        transfer_block_weights(source_conv.bn, target_conv.bn)\n",
    "\n",
    "def transfer_residual_block_weights(source_rb: ResidualBlock, target_rb: ResidualBlock) -> None:\n",
    "    \"\"\"\n",
    "    Copy weights for Residual Block.\n",
    "\n",
    "    Args:\n",
    "        source_rb (ResidualBlock): Source Residual Block\n",
    "        target_rb (ResidualBlock): Target Residual Block\n",
    "    \"\"\"\n",
    "    # Handle main conv path\n",
    "    if hasattr(source_rb, 'conv') and source_rb.conv:\n",
    "        transfer_block_weights(source_rb.conv, target_rb.conv)\n",
    "    \n",
    "    # Handle shortcut if not identity\n",
    "    if hasattr(source_rb, 'shortcut') and source_rb.shortcut:\n",
    "        if not isinstance(source_rb.shortcut, IdentityLayer):  \n",
    "            transfer_block_weights(source_rb.shortcut, target_rb.shortcut)\n",
    "\n",
    "def transfer_mb_conv_weights(source_mb: MBConvLayer, target_mb: MBConvLayer) -> None:\n",
    "    \"\"\"Copy weights for Mobile Inverted Bottleneck Conv Layer.\n",
    "\n",
    "    Args:\n",
    "        source_mb (MBConvLayer): Source MBConv layer\n",
    "        target_mb (MBConvLayer): Target MBConv layer\n",
    "    \"\"\"\n",
    "    # Handle inverted bottleneck\n",
    "    if hasattr(source_mb, \"inverted_bottleneck\") and source_mb.inverted_bottleneck:\n",
    "        transfer_block_weights(\n",
    "            source_mb.inverted_bottleneck, target_mb.inverted_bottleneck\n",
    "        )\n",
    "\n",
    "    # Handle depth-wise conv\n",
    "    if hasattr(source_mb, \"depth_conv\") and source_mb.depth_conv:\n",
    "        transfer_block_weights(source_mb.depth_conv, target_mb.depth_conv)\n",
    "\n",
    "    # Handle point-wise conv\n",
    "    if hasattr(source_mb, \"point_linear\") and source_mb.point_linear:\n",
    "        transfer_block_weights(source_mb.point_linear, target_mb.point_linear)\n",
    "\n",
    "    # Handle SE module if present\n",
    "    if hasattr(source_mb, \"se\") and source_mb.se:\n",
    "        transfer_block_weights(source_mb.se, target_mb.se)\n",
    "\n",
    "def transfer_sequential_weights(source_seq: nn.Sequential, target_seq: nn.Sequential) -> None:\n",
    "    \"\"\"\n",
    "    Copy weights for Sequential container.\n",
    "\n",
    "    ### Args:\n",
    "        `source_seq (nn.Sequential)`: Source Sequential container\n",
    "        `target_seq (nn.Sequential)`: Target Sequential container\n",
    "    \"\"\"\n",
    "    for source_block, target_block in zip(source_seq.children(), target_seq.children()):\n",
    "        transfer_block_weights(source_block, target_block)\n",
    "\n",
    "def transfer_block_weights(source_block: nn.Module, target_block: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Transfer weights from source to target block, handling the different block types.\n",
    "\n",
    "    ### Args:\n",
    "        `source_block (nn.Module)`: Source block from base network\n",
    "        `target_block (nn.Module)`: Target block from expanded network\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(source_block, nn.Sequential):\n",
    "        transfer_sequential_weights(source_block, target_block)\n",
    "\n",
    "    elif isinstance(source_block, nn.Conv2d):\n",
    "        transfer_conv_weights(source_block, target_block)\n",
    "\n",
    "    elif isinstance(source_block, nn.BatchNorm2d):\n",
    "        transfer_bn_weights(source_block, target_block)\n",
    "\n",
    "    elif isinstance(source_block, nn.Linear):\n",
    "        transfer_linear_weights(source_block, target_block)\n",
    "\n",
    "    elif isinstance(source_block, LinearLayer):\n",
    "        transfer_linear_weights(source_block.linear, target_block.linear)\n",
    "\n",
    "    elif isinstance(source_block, SEModule):\n",
    "        transfer_se_module_weights(source_block, target_block)\n",
    "\n",
    "    elif isinstance(source_block, ConvLayer):\n",
    "        transfer_convlayer_weights(source_block, target_block)\n",
    "        \n",
    "    elif isinstance(source_block, ResidualBlock):\n",
    "        transfer_residual_block_weights(source_block, target_block)\n",
    "\n",
    "    elif isinstance(source_block, MBConvLayer):\n",
    "        transfer_mb_conv_weights(source_block, target_block)\n",
    "\n",
    "    elif isinstance(\n",
    "        source_block,\n",
    "        (IdentityLayer, nn.Identity, nn.ReLU, Hsigmoid, Hswish, MyGlobalAvgPool2d),\n",
    "    ):\n",
    "        # Activation layers don't have weights to transfer\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: Unhandled layer type: {type(source_block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3a23575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1:\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def are_blocks_same(bblock, eblock):\n",
    "    # Compare number of parameters\n",
    "    base_params = sum(p.numel() for p in bblock.parameters())\n",
    "    expanded_params = sum(p.numel() for p in eblock.parameters())\n",
    "\n",
    "    # Compare output shapes by checking conv layers\n",
    "    base_shapes = [m.weight.shape for m in bblock.modules() if hasattr(m, \"weight\")]\n",
    "    expanded_shapes = [m.weight.shape for m in eblock.modules() if hasattr(m, \"weight\")]\n",
    "\n",
    "    # Are the same\n",
    "    return (base_shapes == expanded_shapes) and (base_params == expanded_params)\n",
    "\n",
    "\n",
    "for i, (bblock, eblock) in enumerate(zip(base_network.blocks, expanded_network.blocks)):\n",
    "    same_blocks = are_blocks_same(bblock, eblock)\n",
    "\n",
    "    transfer_block_weights(bblock, eblock)\n",
    "\n",
    "    if not same_blocks:\n",
    "        print(f\"Block {i}:\")\n",
    "        print(bblock)\n",
    "        print(eblock)\n",
    "        print(\"=\" * 50)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294da3c",
   "metadata": {},
   "source": [
    "The transfer of the weights needs to be done in oder:\n",
    "`ksize` -> `width` -> `depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2d30620-334d-4e08-9335-3ce2e0bf393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "      (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (se): SE(channel=72, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (se): SE(channel=120, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (se): SE(channel=96, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=160, bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (se): SE(channel=120, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=120, bias=False)\n",
      "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "      (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=320, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(320, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=672, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "      (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=240, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(240, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(672, 672, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=672, bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=672, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=672, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(960, 960, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=960, bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=960, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(672, 672, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=672, bias=False)\n",
      "      (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=672, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(960, 960, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=960, bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=960, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(960, 960, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=960, bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=960, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n",
      "ResidualBlock(\n",
      "  (conv): MBConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(960, 960, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=960, bias=False)\n",
      "      (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): Hswish()\n",
      "      (se): SE(channel=960, reduction=4)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): IdentityLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "max_blocks = max(len(base_network.blocks) - 1, len(expanded_network.blocks) - 1 )\n",
    "\n",
    "for i in range(max_blocks):\n",
    "    if i < len(base_network.blocks[1:]):\n",
    "        print(base_network.blocks[1:][i])\n",
    "    print(expanded_network.blocks[1:][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bde3e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base architecture: {'depths': [3, 3, 3, 3, 3], 'ksizes': [5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 5, 3], 'widths': [3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 3, 4, 3], 'resolution': 152}\n",
      "Block 4 was expanded from depth 3 to 4\n"
     ]
    }
   ],
   "source": [
    "# Get the base and expanded depths\n",
    "base_depths = base_arch[\"depths\"]\n",
    "expanded_depths = expanded_arch[\"depths\"]\n",
    "\n",
    "# Find where the depth increased\n",
    "added_block_idx = None\n",
    "for i, (base_d, exp_d) in enumerate(zip(base_depths, expanded_depths)):\n",
    "    if exp_d > base_d:\n",
    "        added_block_idx = i\n",
    "        break\n",
    "\n",
    "print(f\"Base architecture: {base_arch}\")\n",
    "print(f\"Block {added_block_idx} was expanded from depth {base_depths[added_block_idx]} to {expanded_depths[added_block_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9ad9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last common block is: 16\n"
     ]
    }
   ],
   "source": [
    "last_common_block = 1 + sum(base_arch[\"depths\"][:added_block_idx]) + base_arch[\"depths\"][added_block_idx]\n",
    "print(f\"The last common block is: {last_common_block}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdd0b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network.blocks.insert(\n",
    "    last_common_block,\n",
    "    base_network.blocks[last_common_block - 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40313640",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (base_block, expanded_block) in enumerate(zip(base_network.blocks, expanded_network.blocks)):\n",
    "    # print(base_block)\n",
    "    # print(expanded_block)\n",
    "    # print(\"=\" * 50)\n",
    "    try:\n",
    "        transfer_block_weights(base_block, expanded_block)\n",
    "\n",
    "    except RuntimeError:\n",
    "        print(f\"Block {i}:\")\n",
    "        print(base_block)\n",
    "        print(expanded_block)\n",
    "        print(\"=\" * 50)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd68d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
