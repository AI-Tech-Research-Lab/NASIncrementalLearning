{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fsahli/vvcastro/continual-nas\n"
     ]
    }
   ],
   "source": [
    "from _configs import OFA_MODEL_PATH\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _constants import DATASET_N_CLASSES\n",
    "\n",
    "from continual_learning.continual_trainers import GrowingDataContinualTrainer\n",
    "from search_space.base_ofa import OFAEvaluator\n",
    "from search_space import get_search_space\n",
    "from tools.metrics import binary_accuracy\n",
    "from _utils import set_seed\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "OFA_FAMILY = \"mobilenetv3\"\n",
    "\n",
    "# These settings vary with the env we run the code\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "def main(\n",
    "    dataset: str,\n",
    "    n_tasks: int,\n",
    "    optimiser_name: str,\n",
    "    learning_rate: float,\n",
    "    weight_decay: float,\n",
    "    epochs_per_task: int,\n",
    "    random_seed: int,\n",
    "    show_progress: bool,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Main function to initialize the trainer and start the training process.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"Running with D: {dataset}, n_tasks: {n_tasks}, \"\n",
    "        f\"optimiser_name: {optimiser_name}, learning_rate: {learning_rate}, \"\n",
    "        f\"weight_decay: {weight_decay}, epochs_per_task: {epochs_per_task}, \"\n",
    "        f\"random_seed: {random_seed}\"\n",
    "    )\n",
    "    set_seed(random_seed)\n",
    "\n",
    "    search_space = get_search_space(family=OFA_FAMILY, fixed=False)\n",
    "    ofa_net = OFAEvaluator(\n",
    "        family=OFA_FAMILY,\n",
    "        model_path=OFA_MODEL_PATH,\n",
    "        data_classes=DATASET_N_CLASSES[dataset],\n",
    "        pretrained=True,\n",
    "    )\n",
    "\n",
    "    # Step 0: Sample an architecture\n",
    "    sampled_architecture = search_space.sample(n_samples=8)[2]\n",
    "    print(f\"Sampled dir: {sampled_architecture['direction']}\")\n",
    "    base_model = ofa_net.get_architecture_model(sampled_architecture)\n",
    "\n",
    "    # Step 1. Load the trainer with the dataset\n",
    "    trainer = GrowingDataContinualTrainer(\n",
    "        capacity_tau=0.08,\n",
    "        expand_is_frozen=False,\n",
    "        distill_on_expand=False,\n",
    "        weights_from_ofa=True,\n",
    "        dataset_name=dataset,\n",
    "        search_space_family=OFA_FAMILY,\n",
    "        experiment_dir=\"tmp\",\n",
    "        experiment_name=f\"ND{n_tasks}-ep{epochs_per_task}@{dataset}\",\n",
    "        model_definition=sampled_architecture,\n",
    "        base_model=base_model,\n",
    "        num_tasks=n_tasks,\n",
    "        random_seed=random_seed,\n",
    "    )\n",
    "\n",
    "    # Load the data and the stats to use for normalisation\n",
    "    trainer.load_dataset(dataset_name=dataset)\n",
    "\n",
    "    # Set training settings\n",
    "    trainer.set_experiment_settings(\n",
    "        loss_fn=nn.CrossEntropyLoss(),\n",
    "        epochs_per_task=epochs_per_task,\n",
    "        optim_name=optimiser_name,\n",
    "        optim_params={\"lr\": learning_rate, \"weight_decay\": weight_decay},\n",
    "        model_size_metrics={\n",
    "            \"model_size\": sum([p.numel() for p in base_model.parameters()]),\n",
    "        },\n",
    "        training_metrics={\"accuracy\": binary_accuracy},\n",
    "        augment=False,\n",
    "    )\n",
    "\n",
    "    # Step 5: Train the model (random and continual)\n",
    "    trainer.train(\n",
    "        task_epochs=epochs_per_task,\n",
    "        show_progress=show_progress,\n",
    "        with_random_metrics=False,\n",
    "        evaluate_after_task=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoding = [\n",
    "    \"1\",\n",
    "    \"1\",\n",
    "    \"1\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"1\",\n",
    "    \"1\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    \"9\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "]\n",
    "\n",
    "model_encoding = [int(bit) for bit in model_encoding]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with D: cifar10, n_tasks: 10, optimiser_name: adam, learning_rate: 0.00075, weight_decay: 1e-05, epochs_per_task: 1, random_seed: 42\n",
      "Sampled dir: [1, 1, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:06<00:00, 25.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.6985 ± 0.4288\n",
      "\taccuracy: 0.7566 ± 0.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:05<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.4539 ± 0.1682\n",
      "\taccuracy: 0.8370 ± 0.0705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:05<00:00, 26.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3834 ± 0.1666\n",
      "\taccuracy: 0.8702 ± 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:05<00:00, 26.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3706 ± 0.1745\n",
      "\taccuracy: 0.8806 ± 0.0568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:05<00:00, 26.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3122 ± 0.1715\n",
      "\taccuracy: 0.9001 ± 0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:06<00:00, 25.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3587 ± 0.2073\n",
      "\taccuracy: 0.8830 ± 0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:06<00:00, 25.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3282 ± 0.1618\n",
      "\taccuracy: 0.8893 ± 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:06<00:00, 24.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3207 ± 0.1584\n",
      "\taccuracy: 0.8945 ± 0.0572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:06<00:00, 24.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3213 ± 0.1742\n",
      "\taccuracy: 0.8945 ± 0.0570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [00:06<00:00, 24.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metrics:\n",
      "\tLoss: 0.3004 ± 0.1431\n",
      "\taccuracy: 0.8969 ± 0.0577\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "main(\n",
    "    dataset=\"cifar10\",\n",
    "    n_tasks=10,\n",
    "    optimiser_name=\"adam\",\n",
    "    learning_rate=7.5e-4,\n",
    "    weight_decay=1e-5,\n",
    "    epochs_per_task=1,\n",
    "    random_seed=42,\n",
    "    show_progress=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "continual-nas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
